{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0621a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data files loaded successfully.\n",
      "\n",
      "--- Starting Data Cleaning and Preprocessing ---\n",
      "Date columns converted to datetime objects.\n",
      "\n",
      "--- Engineering Features ---\n",
      "Feature engineering complete.\n",
      "\n",
      "--- Preparing Model Training and Test Sets ---\n",
      "Filtered transactions for dbd = 15. Shape: (73100, 18)\n",
      "Final training data shape after merge: (67200, 19)\n",
      "Final test data shape after merge: (5900, 19)\n",
      "\n",
      "--- Training XGBoost Model ---\n",
      "Model training complete.\n",
      "\n",
      "Final Training RMSE: 304.6268\n",
      "\n",
      "--- Generating Predictions and Submission File ---\n",
      "Submission file 'submission_file.csv' created successfully.\n",
      "\n",
      "Top 5 rows of the submission file:\n",
      "          route_key  final_seatcount\n",
      "0  2025-02-11_46_45             3732\n",
      "1  2025-01-20_17_23             1629\n",
      "2  2025-01-08_02_14             1171\n",
      "3  2025-01-08_08_47              962\n",
      "4  2025-01-08_09_46             3305\n",
      "\n",
      "--- Top 15 Feature Importances ---\n",
      "        Value      Feature\n",
      "114  0.035489   route_46_9\n",
      "135  0.030618   route_9_46\n",
      "144  0.029741      srcid_9\n",
      "188  0.027359     destid_9\n",
      "99   0.027158  route_45_46\n",
      "177  0.026984     srcid_45\n",
      "169  0.026830     srcid_37\n",
      "111  0.025360  route_46_45\n",
      "225  0.024738    destid_48\n",
      "215  0.023375    destid_37\n",
      "121  0.023267  route_47_45\n",
      "113  0.022572  route_46_48\n",
      "100  0.020462  route_45_47\n",
      "79   0.020332  route_36_37\n",
      "82   0.019073  route_37_36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Updated file paths based on your new code structure.\n",
    "try:\n",
    "    df_train = pd.read_csv('training_data/train/train.csv')\n",
    "    df_transactions = pd.read_csv('training_data/train/transactions.csv')\n",
    "    df_test = pd.read_csv('testing data/test_8gqdJqH.csv')\n",
    "    print(\"All data files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data files: {e}\")\n",
    "    print(\"Please ensure your folder structure and file names are correct.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Initial Data Cleaning & Type Conversion ---\n",
    "print(\"\\n--- Starting Data Cleaning and Preprocessing ---\")\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "for df in [df_train, df_transactions, df_test]:\n",
    "    df['doj'] = pd.to_datetime(df['doj'])\n",
    "if 'doi' in df_transactions.columns:\n",
    "    df_transactions['doi'] = pd.to_datetime(df_transactions['doi'])\n",
    "\n",
    "print(\"Date columns converted to datetime objects.\")\n",
    "\n",
    "# --- 3. Feature Engineering Function ---\n",
    "# We create a function to apply the same transformations to both train and test data\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates time-series and categorical features from the dataframe.\n",
    "    \"\"\"\n",
    "    df['month'] = df['doj'].dt.month\n",
    "    df['year'] = df['doj'].dt.year\n",
    "    df['day_of_week'] = df['doj'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    df['day_of_year'] = df['doj'].dt.dayofyear\n",
    "    df['week_of_year'] = df['doj'].dt.isocalendar().week.astype(int)\n",
    "    df['is_weekend'] = (df['doj'].dt.dayofweek >= 5).astype(int) # Saturday or Sunday\n",
    "    \n",
    "    # Create a unique route identifier\n",
    "    df['route'] = df['srcid'].astype(str) + '_' + df['destid'].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\n--- Engineering Features ---\")\n",
    "# Apply full feature engineering to the transactions data\n",
    "df_transactions = create_features(df_transactions)\n",
    "\n",
    "# For the test set, we only need to create the 'route' column for the merge key.\n",
    "# The other features (month, year, etc.) will come from the transaction data after the merge.\n",
    "df_test['route'] = df_test['srcid'].astype(str) + '_' + df_test['destid'].astype(str)\n",
    "print(\"Feature engineering complete.\")\n",
    "\n",
    "# --- 4. Prepare Training and Test Data ---\n",
    "print(\"\\n--- Preparing Model Training and Test Sets ---\")\n",
    "\n",
    "# Filter transactions for data available exactly 15 days before departure\n",
    "dbd_filter = 15\n",
    "df_transactions_filtered = df_transactions[df_transactions['dbd'] == dbd_filter].copy()\n",
    "\n",
    "print(f\"Filtered transactions for dbd = {dbd_filter}. Shape: {df_transactions_filtered.shape}\")\n",
    "\n",
    "# Create the training set by merging filtered transactions with train labels\n",
    "df_model_train = pd.merge(\n",
    "    df_train,\n",
    "    df_transactions_filtered,\n",
    "    on=['doj', 'srcid', 'destid'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Final training data shape after merge: {df_model_train.shape}\")\n",
    "if df_model_train.shape[0] != df_train.shape[0]:\n",
    "    print(\"Warning: Some routes in train.csv did not have a transaction record at dbd=15.\")\n",
    "\n",
    "# Create the test set by merging filtered transactions with test routes\n",
    "df_model_test = pd.merge(\n",
    "    df_test,\n",
    "    df_transactions_filtered,\n",
    "    on=['doj', 'srcid', 'destid', 'route'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Final test data shape after merge: {df_model_test.shape}\")\n",
    "if df_model_test.isnull().sum().sum() > 0:\n",
    "    print(\"Warning: Some test routes have missing features. Filling with 0.\")\n",
    "    df_model_test.fillna(0, inplace=True)\n",
    "\n",
    "# --- 5. Model Training (XGBoost) ---\n",
    "print(\"\\n--- Training XGBoost Model ---\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "# We will one-hot encode the categorical features for XGBoost\n",
    "features = [\n",
    "    'srcid', 'destid', 'cumsum_seatcount', 'cumsum_searchcount',\n",
    "    'month', 'year', 'day_of_week', 'day_of_year', 'week_of_year', 'is_weekend',\n",
    "    'srcid_region', 'destid_region', 'srcid_tier', 'destid_tier', 'route'\n",
    "]\n",
    "categorical_features = ['srcid_region', 'destid_region', 'srcid_tier', 'destid_tier', 'route', 'srcid', 'destid']\n",
    "\n",
    "X = df_model_train[features]\n",
    "y_train = df_model_train['final_seatcount']\n",
    "X_test_prep = df_model_test[features]\n",
    "\n",
    "# One-Hot Encode categorical features\n",
    "X_train = pd.get_dummies(X, columns=categorical_features, dummy_na=False)\n",
    "X_test = pd.get_dummies(X_test_prep, columns=categorical_features, dummy_na=False)\n",
    "\n",
    "# Align columns - crucial for ensuring test set has same features as train set\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# XGBoost Model Parameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist', # Use 'hist' for faster training\n",
    "    'early_stopping_rounds': 100 # Moved parameter here\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "# Train the model with early stopping\n",
    "# The early_stopping_rounds parameter from the constructor will be used here.\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train)],\n",
    "          verbose=False)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "print(f\"\\nFinal Training RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "# --- 6. Prediction and Submission File Creation ---\n",
    "print(\"\\n--- Generating Predictions and Submission File ---\")\n",
    "\n",
    "# Predict on the test data\n",
    "# The model automatically uses the best iteration thanks to early stopping\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Post-processing: Ensure predictions are non-negative integers\n",
    "predictions[predictions < 0] = 0\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Create the submission file\n",
    "submission_df = pd.DataFrame({'route_key': df_model_test['route_key'], 'final_seatcount': predictions})\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission_file.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission_file.csv' created successfully.\")\n",
    "print(\"\\nTop 5 rows of the submission file:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# --- 7. (Optional) Feature Importance ---\n",
    "print(\"\\n--- Top 15 Feature Importances ---\")\n",
    "feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': X_train.columns})\n",
    "print(feature_imp.sort_values(by=\"Value\", ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808422a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93764b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
